# Week 1: Python + ML ê¸°ì´ˆ (56ì‹œê°„)

> **ëª©í‘œ:** Python ë°ì´í„° ê³¼í•™ + Scikit-learn + PyTorch ê¸°ì´ˆ ì™„ì„±

## ğŸ“… ì£¼ì°¨ ì¼ì •

### Day 1-2 (ì›”-í™”): Python ë°ì´í„° ê³¼í•™ ë„êµ¬ ë§ˆìŠ¤í„°
**í•™ìŠµ ì‹œê°„:** 16ì‹œê°„
- NumPy ê³ ê¸‰ ì—°ì‚°
- Pandas DataFrame ì¡°ì‘
- Matplotlib/Seaborn ì‹œê°í™”

### Day 3-4 (ìˆ˜-ëª©): Scikit-learn + ì „í†µ ML
**í•™ìŠµ ì‹œê°„:** 16ì‹œê°„
- ë°ì´í„° ì „ì²˜ë¦¬
- Logistic Regression, Random Forest
- ëª¨ë¸ í‰ê°€ (Precision, Recall, F1)

### Day 5-7 (ê¸ˆ-ì¼): PyTorch ê¸°ì´ˆ + ë”¥ëŸ¬ë‹ ì…ë¬¸
**í•™ìŠµ ì‹œê°„:** 24ì‹œê°„
- Tensor ì—°ì‚°
- ì‹ ê²½ë§ êµ¬í˜„
- MNIST ë¶„ë¥˜

## ğŸ¯ í•™ìŠµ ëª©í‘œ

### í•µì‹¬ ì—­ëŸ‰
- âœ… Pandasë¡œ ê¸ˆìœµ ë°ì´í„° ì „ì²˜ë¦¬
- âœ… NumPy ë²¡í„° ì—°ì‚° ë§ˆìŠ¤í„°
- âœ… Scikit-learn ML íŒŒì´í”„ë¼ì¸
- âœ… PyTorch ì‹ ê²½ë§ êµ¬í˜„

### ì™„ì„± í”„ë¡œì íŠ¸
1. **ì£¼ì‹ ë°ì´í„° ë¶„ì„** - Pandas, NumPy
2. **ì‹ ìš© í‰ê°€ ëª¨ë¸** - Scikit-learn
3. **PyTorch MNIST** - PyTorch ê¸°ì´ˆ

## ğŸ“š í•™ìŠµ ê°•ì˜

### Day 1-2 (6ì‹œê°„ ê°•ì˜)
- Coursera: "Python for Data Science" (ì†ì„±)
- YouTube: ìƒí™œì½”ë”© Numpy/Pandas (í•µì‹¬ë§Œ)

### Day 3-4 (6ì‹œê°„ ê°•ì˜)
- Coursera: Machine Learning (Andrew Ng) Week 1-2
- Fast.ai: Tabular Learner

### Day 5-7 (9ì‹œê°„ ê°•ì˜)
- PyTorch ê³µì‹ íŠœí† ë¦¬ì–¼ (60ë¶„ ë¸”ë¦¬ì¸ )
- DeepLearning.AI: Neural Networks Basics
- Fast.ai Lesson 1-2

## ğŸ› ï¸ í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜

```bash
conda activate ai-dev

# Day 1-2
pip install numpy pandas matplotlib seaborn scikit-learn jupyter yfinance

# Day 3-4
conda install scikit-learn -y

# Day 5-7
conda install pytorch torchvision torchaudio -c pytorch -y
```

## ğŸ’» ì‹¤ìŠµ í”„ë¡œì íŠ¸

### Project 1: ê¸ˆìœµ ë°ì´í„° ë¶„ì„ (Day 1-2)

**íŒŒì¼:** `stock_analysis.ipynb`

```python
"""
ì£¼ì‹ ë°ì´í„° ë¶„ì„ í”„ë¡œì íŠ¸
1. yfinanceë¡œ ì€í–‰ ì£¼ê°€ ìˆ˜ì§‘
2. Pandas ì „ì²˜ë¦¬
3. NumPy ì§€í‘œ ê³„ì‚° (ì´ë™í‰ê· , ë³¼ë¦°ì €ë°´ë“œ)
4. Matplotlib ì‹œê°í™”
5. ìƒê´€ê´€ê³„ ë¶„ì„
"""

import yfinance as yf
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# ì‹ í•œì€í–‰, êµ­ë¯¼ì€í–‰ ì£¼ê°€
tickers = ['055550.KS', '105560.KS']
data = yf.download(tickers, start='2023-01-01', end='2024-01-01')

# ì´ë™í‰ê· ì„ 
data['MA20'] = data['Close'].rolling(window=20).mean()
data['MA60'] = data['Close'].rolling(window=60).mean()

# ë³¼ë¦°ì € ë°´ë“œ
data['Upper'] = data['MA20'] + 2*data['Close'].rolling(window=20).std()
data['Lower'] = data['MA20'] - 2*data['Close'].rolling(window=20).std()

# ì‹œê°í™”
plt.figure(figsize=(15, 7))
plt.plot(data.index, data['Close'], label='Close Price')
plt.plot(data.index, data['MA20'], label='MA20')
plt.plot(data.index, data['MA60'], label='MA60')
plt.legend()
plt.show()
```

**ì²´í¬í¬ì¸íŠ¸:**
- [ ] yfinanceë¡œ ë°ì´í„° ìˆ˜ì§‘
- [ ] Pandas DataFrame ì¡°ì‘ ìˆ™ë ¨
- [ ] NumPy ê³„ì‚° êµ¬í˜„
- [ ] ì‹œê°í™” ì™„ì„±

---

### Project 2: ì‹ ìš© í‰ê°€ ëª¨ë¸ (Day 3-4)

**íŒŒì¼:** `credit_scoring.ipynb`

```python
"""
ì‹ ìš© í‰ê°€ ëª¨ë¸ í”„ë¡œì íŠ¸
Dataset: Kaggle - Credit Card Default
1. ë°ì´í„° ì „ì²˜ë¦¬ (ê²°ì¸¡ì¹˜, ìŠ¤ì¼€ì¼ë§)
2. Train/Test ë¶„í• 
3. Random Forest í•™ìŠµ
4. ëª¨ë¸ í‰ê°€
"""

from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report, confusion_matrix
import pandas as pd

# ë°ì´í„° ë¡œë“œ
df = pd.read_csv('credit_data.csv')

# ì „ì²˜ë¦¬
X = df.drop('default', axis=1)
y = df['default']

# ìŠ¤ì¼€ì¼ë§
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Train/Test ë¶„í• 
X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y, test_size=0.2, random_state=42
)

# ëª¨ë¸ í•™ìŠµ
rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)

# í‰ê°€
y_pred = rf_model.predict(X_test)
print(classification_report(y_test, y_pred))

# Cross-validation
cv_scores = cross_val_score(rf_model, X_scaled, y, cv=5)
print(f'CV Scores: {cv_scores.mean():.4f} (+/- {cv_scores.std():.4f})')
```

**ì²´í¬í¬ì¸íŠ¸:**
- [ ] ë°ì´í„° ì „ì²˜ë¦¬ ì™„ë£Œ
- [ ] ML íŒŒì´í”„ë¼ì¸ êµ¬ì¶•
- [ ] ëª¨ë¸ í‰ê°€ ì§€í‘œ ì´í•´
- [ ] Cross-validation ì ìš©

---

### Project 3: PyTorch MNIST (Day 5-7)

**íŒŒì¼:** `pytorch_basics.ipynb`

```python
"""
PyTorch MNIST ë¶„ë¥˜
1. Tensor ì—°ì‚° ë§ˆìŠ¤í„°
2. ì‹ ê²½ë§ êµ¬í˜„
3. í•™ìŠµ/ê²€ì¦ íŒŒì´í”„ë¼ì¸
4. 95% ì´ìƒ ì •í™•ë„ ë‹¬ì„±
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from torchvision import datasets, transforms

# 1. ë°ì´í„° ë¡œë“œ
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.1307,), (0.3081,))
])

train_dataset = datasets.MNIST(
    './data', train=True, download=True, transform=transform
)
test_dataset = datasets.MNIST(
    './data', train=False, transform=transform
)

train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=False)

# 2. ì‹ ê²½ë§ ì •ì˜
class SimpleNN(nn.Module):
    def __init__(self):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(784, 128)
        self.fc2 = nn.Linear(128, 64)
        self.fc3 = nn.Linear(64, 10)
        self.relu = nn.ReLU()
        self.dropout = nn.Dropout(0.2)
    
    def forward(self, x):
        x = x.view(-1, 784)
        x = self.relu(self.fc1(x))
        x = self.dropout(x)
        x = self.relu(self.fc2(x))
        x = self.dropout(x)
        x = self.fc3(x)
        return x

# 3. í•™ìŠµ ë£¨í”„
def train(model, device, train_loader, optimizer, epoch):
    model.train()
    for batch_idx, (data, target) in enumerate(train_loader):
        data, target = data.to(device), target.to(device)
        optimizer.zero_grad()
        output = model(data)
        loss = nn.CrossEntropyLoss()(output, target)
        loss.backward()
        optimizer.step()
        
        if batch_idx % 100 == 0:
            print(f'Epoch: {epoch}, Batch: {batch_idx}, Loss: {loss.item():.4f}')

# 4. í‰ê°€
def test(model, device, test_loader):
    model.eval()
    test_loss = 0
    correct = 0
    with torch.no_grad():
        for data, target in test_loader:
            data, target = data.to(device), target.to(device)
            output = model(data)
            test_loss += nn.CrossEntropyLoss()(output, target).item()
            pred = output.argmax(dim=1, keepdim=True)
            correct += pred.eq(target.view_as(pred)).sum().item()
    
    accuracy = 100. * correct / len(test_loader.dataset)
    print(f'Test Accuracy: {accuracy:.2f}%')
    return accuracy

# 5. ì‹¤í–‰
device = torch.device("mps" if torch.backends.mps.is_available() else "cpu")
model = SimpleNN().to(device)
optimizer = optim.Adam(model.parameters(), lr=0.001)

for epoch in range(1, 11):
    train(model, device, train_loader, optimizer, epoch)
    accuracy = test(model, device, test_loader)
```

**ì²´í¬í¬ì¸íŠ¸:**
- [ ] PyTorch Tensor ì—°ì‚° ì´í•´
- [ ] ì‹ ê²½ë§ êµ¬ì¡° êµ¬í˜„
- [ ] í•™ìŠµ/ê²€ì¦ íŒŒì´í”„ë¼ì¸
- [ ] 95% ì´ìƒ ì •í™•ë„ ë‹¬ì„±

---

## âœ… Week 1 ì™„ë£Œ ì²´í¬ë¦¬ìŠ¤íŠ¸

### í”„ë¡œì íŠ¸ ì™„ì„±ë„
- [ ] Project 1: ì£¼ì‹ ë°ì´í„° ë¶„ì„ âœ…
- [ ] Project 2: ì‹ ìš© í‰ê°€ ëª¨ë¸ âœ…
- [ ] Project 3: PyTorch MNIST 95%+ âœ…

### ê¸°ìˆ  ìŠµë“
- [ ] Pandas DataFrame ììœ ìì¬
- [ ] NumPy ë²¡í„° ì—°ì‚° ë§ˆìŠ¤í„°
- [ ] Scikit-learn íŒŒì´í”„ë¼ì¸
- [ ] PyTorch Tensor & ì‹ ê²½ë§

### GitHub
- [ ] 3ê°œ í”„ë¡œì íŠ¸ ì»¤ë°‹
- [ ] README ì‘ì„±
- [ ] í•™ìŠµ ë…¸íŠ¸ ì •ë¦¬

### ë‹¤ìŒ ì£¼ ì¤€ë¹„
- [ ] Week 2 ê³„íš í™•ì¸
- [ ] CNN ê°œë… ì˜ˆìŠµ
- [ ] LSTM ì´ë¡  í•™ìŠµ

## ğŸ”— ì°¸ê³  ìë£Œ

- [Pandas ê³µì‹ ë¬¸ì„œ](https://pandas.pydata.org/docs/)
- [Scikit-learn íŠœí† ë¦¬ì–¼](https://scikit-learn.org/stable/tutorial/)
- [PyTorch íŠœí† ë¦¬ì–¼](https://pytorch.org/tutorials/)
- [Kaggle Credit Card Dataset](https://www.kaggle.com/datasets)

## ğŸ“Š í•™ìŠµ ì‹œê°„ ê¸°ë¡

| ì¼ì | í™œë™ | ì‹œê°„ | ì™„ë£Œ |
|------|------|------|------|
| Day 1 | NumPy, Pandas ê°•ì˜ + ì‹¤ìŠµ | 8h | [ ] |
| Day 2 | ì£¼ì‹ ë¶„ì„ í”„ë¡œì íŠ¸ | 8h | [ ] |
| Day 3 | Scikit-learn ê°•ì˜ | 8h | [ ] |
| Day 4 | ì‹ ìš© í‰ê°€ ëª¨ë¸ | 8h | [ ] |
| Day 5 | PyTorch ê¸°ì´ˆ | 8h | [ ] |
| Day 6 | MNIST í”„ë¡œì íŠ¸ | 8h | [ ] |
| Day 7 | ë³µìŠµ & ì •ë¦¬ | 8h | [ ] |

---

**Week 1 ì™„ë£Œ í›„ â†’ Week 2 (PyTorch ì‹¬í™” + BERT)ë¡œ ì§„í–‰**

# Week 3: BERT + NLP ì‹¬í™” (56ì‹œê°„)

> **ëª©í‘œ:** Week 2ì—ì„œ ë°°ìš´ BERTë¥¼ ì‹¤ì „ ê¸ˆìœµ í”„ë¡œì íŠ¸ì— ì‹¬í™” ì ìš©

## ğŸ“… ì£¼ì°¨ ì¼ì •

### Day 15-17 (ì›”-ìˆ˜): BERT ê³ ê¸‰ ê¸°ë²•
**í•™ìŠµ ì‹œê°„:** 24ì‹œê°„
- Multi-task Learning
- Domain Adaptation
- Model Optimization

### Day 18-21 (ëª©-ì¼): ì‹¤ì „ ê¸ˆìœµ NLP í”„ë¡œì íŠ¸
**í•™ìŠµ ì‹œê°„:** 32ì‹œê°„
- ê¸ˆìœµ ë¬¸ì„œ ë¶„ë¥˜ ì‹œìŠ¤í…œ
- ë¦¬ìŠ¤í¬ í‰ê°€ ìë™í™”
- ê·œì œ ë¬¸ì„œ ë¶„ì„

## ğŸ¯ í•™ìŠµ ëª©í‘œ

### í•µì‹¬ ì—­ëŸ‰
- âœ… BERT ê³ ê¸‰ ê¸°ë²• (Multi-task, Domain Adaptation)
- âœ… ê¸ˆìœµ ë„ë©”ì¸ NLP íŒŒì´í”„ë¼ì¸
- âœ… ëª¨ë¸ ìµœì í™” (Quantization, Pruning)
- âœ… í”„ë¡œë•ì…˜ ë ˆë²¨ ì½”ë“œ

### ì™„ì„± í”„ë¡œì íŠ¸
- **ê¸ˆìœµ ë¬¸ì„œ í†µí•© ë¶„ë¥˜ ì‹œìŠ¤í…œ**
- **ê³„ì•½ì„œ ë¦¬ìŠ¤í¬ ìë™ í‰ê°€**
- **ê·œì œ ì¤€ìˆ˜ ë¶„ì„ ë„êµ¬**

## ğŸ’¡ Week 2 ë³µìŠµ + ì‹¬í™”

Week 2ì—ì„œ ë°°ìš´ ë‚´ìš©ì„ ë”ìš± ì‹¬í™”í•˜ê³  ì‹¤ì „ì— ì ìš©í•˜ëŠ” ì£¼ì°¨ì…ë‹ˆë‹¤.

### Week 2 í•µì‹¬ ë³µìŠµ
1. BERT Fine-tuning ê³¼ì •
2. Hugging Face Trainer API
3. Extractive QA ì›ë¦¬
4. ëª¨ë¸ í‰ê°€ ë©”íŠ¸ë¦­

### Week 3 ì‹¬í™” ë‚´ìš©
1. **Multi-task Learning:** í•˜ë‚˜ì˜ ëª¨ë¸ë¡œ ì—¬ëŸ¬ íƒœìŠ¤í¬ ìˆ˜í–‰
2. **Domain Adaptation:** ê¸ˆìœµ ë„ë©”ì¸ì— íŠ¹í™”ëœ BERT
3. **Model Optimization:** ë°°í¬ë¥¼ ìœ„í•œ ê²½ëŸ‰í™”
4. **End-to-End Pipeline:** ì‹¤ì „ ì‹œìŠ¤í…œ êµ¬ì¶•

## ğŸ’» ì‹¬í™” í”„ë¡œì íŠ¸

### Project 8: ê¸ˆìœµ ë¬¸ì„œ í†µí•© ë¶„ë¥˜ ì‹œìŠ¤í…œ

**ëª©í‘œ:** í•˜ë‚˜ì˜ BERT ëª¨ë¸ë¡œ ì—¬ëŸ¬ ë¶„ë¥˜ ì‘ì—… ë™ì‹œ ìˆ˜í–‰

```python
"""
Multi-task Learning BERT
- Task 1: ë¬¸ì„œ íƒ€ì… ë¶„ë¥˜ (ëŒ€ì¶œ/ë³´í—˜/íˆ¬ì)
- Task 2: ê¸ì •/ë¶€ì • ë¶„ë¥˜
- Task 3: ìš°ì„ ìˆœìœ„ ë¶„ë¥˜ (ê¸´ê¸‰/ì¼ë°˜/ë‚®ìŒ)
"""

import torch
import torch.nn as nn
from transformers import BertModel

class MultiTaskBERT(nn.Module):
    def __init__(self, num_doc_types=5, num_sentiments=3, num_priorities=3):
        super().__init__()
        self.bert = BertModel.from_pretrained("klue/bert-base")
        
        # ê³µìœ  ë ˆì´ì–´
        self.dropout = nn.Dropout(0.3)
        
        # Taskë³„ í—¤ë“œ
        self.doc_classifier = nn.Linear(768, num_doc_types)
        self.sentiment_classifier = nn.Linear(768, num_sentiments)
        self.priority_classifier = nn.Linear(768, num_priorities)
    
    def forward(self, input_ids, attention_mask):
        outputs = self.bert(
            input_ids=input_ids,
            attention_mask=attention_mask
        )
        
        pooled = outputs.pooler_output
        pooled = self.dropout(pooled)
        
        doc_logits = self.doc_classifier(pooled)
        sentiment_logits = self.sentiment_classifier(pooled)
        priority_logits = self.priority_classifier(pooled)
        
        return {
            'doc_type': doc_logits,
            'sentiment': sentiment_logits,
            'priority': priority_logits
        }

# Multi-task Loss
def multi_task_loss(outputs, labels, weights={'doc': 1.0, 'sent': 0.5, 'pri': 0.5}):
    loss_fn = nn.CrossEntropyLoss()
    
    doc_loss = loss_fn(outputs['doc_type'], labels['doc_type'])
    sent_loss = loss_fn(outputs['sentiment'], labels['sentiment'])
    pri_loss = loss_fn(outputs['priority'], labels['priority'])
    
    total_loss = (
        weights['doc'] * doc_loss +
        weights['sent'] * sent_loss +
        weights['pri'] * pri_loss
    )
    
    return total_loss, {
        'doc_loss': doc_loss.item(),
        'sentiment_loss': sent_loss.item(),
        'priority_loss': pri_loss.item(),
        'total_loss': total_loss.item()
    }
```

---

### Project 9: ê³„ì•½ì„œ ë¦¬ìŠ¤í¬ ìë™ í‰ê°€

```python
"""
ê¸ˆìœµ ê³„ì•½ì„œ ë¦¬ìŠ¤í¬ í‰ê°€ ì‹œìŠ¤í…œ
- ë¶ˆê³µì • ì¡°í•­ íƒì§€
- ìœ„í—˜ë„ ì ìˆ˜ ì‚°ì¶œ
- ê°œì„  ê¶Œì¥ì‚¬í•­ ìƒì„±
"""

from transformers import pipeline
import re

class ContractRiskAnalyzer:
    def __init__(self):
        # BERT QA íŒŒì´í”„ë¼ì¸
        self.qa_pipeline = pipeline(
            "question-answering",
            model="klue/roberta-large"
        )
        
        # ê°ì„± ë¶„ì„ (ìœ„í—˜ë„ íŒë‹¨)
        self.sentiment = pipeline(
            "sentiment-analysis",
            model="./financial_sentiment_model"
        )
        
        # ìœ„í—˜ í‚¤ì›Œë“œ
        self.risk_keywords = [
            "ìœ„ì•½ê¸ˆ", "ì—°ì²´", "ê°•ì œì§‘í–‰", "ë‹´ë³´", 
            "ë©´ì±…", "ì œí•œ", "ê¸ˆì§€", "ì˜ë¬´"
        ]
    
    def analyze_contract(self, contract_text):
        """ê³„ì•½ì„œ ì¢…í•© ë¶„ì„"""
        
        # 1. ì£¼ìš” ì¡°í•­ ì¶”ì¶œ
        clauses = self._extract_clauses(contract_text)
        
        # 2. ê° ì¡°í•­ ìœ„í—˜ë„ ë¶„ì„
        risks = []
        for clause in clauses:
            risk_score = self._calculate_risk(clause)
            if risk_score > 0.6:
                risks.append({
                    'clause': clause,
                    'risk_score': risk_score,
                    'keywords': self._find_risk_keywords(clause)
                })
        
        # 3. ì¢…í•© ë¦¬í¬íŠ¸
        report = self._generate_report(risks)
        
        return report
    
    def _calculate_risk(self, text):
        """í…ìŠ¤íŠ¸ ìœ„í—˜ë„ ê³„ì‚°"""
        # ìœ„í—˜ í‚¤ì›Œë“œ ê°œìˆ˜
        keyword_score = sum(1 for kw in self.risk_keywords if kw in text)
        
        # ê°ì„± ë¶„ì„ (ë¶€ì •ì ì¼ìˆ˜ë¡ ìœ„í—˜)
        sentiment = self.sentiment(text)[0]
        sentiment_score = 1 - sentiment['score'] if sentiment['label'] == 'NEGATIVE' else 0
        
        # ë¬¸ì¥ ê¸¸ì´ (ë³µì¡í• ìˆ˜ë¡ ìœ„í—˜)
        length_score = min(len(text) / 500, 1.0)
        
        # ì¢…í•© ì ìˆ˜
        total_score = (
            keyword_score * 0.4 +
            sentiment_score * 0.4 +
            length_score * 0.2
        )
        
        return min(total_score, 1.0)
    
    def _find_risk_keywords(self, text):
        return [kw for kw in self.risk_keywords if kw in text]
    
    def _extract_clauses(self, text):
        """ê³„ì•½ì„œì—ì„œ ì¡°í•­ ì¶”ì¶œ"""
        # ë²ˆí˜¸ê°€ ìˆëŠ” ì¡°í•­ ë¶„ë¦¬
        clauses = re.split(r'\n\s*\d+\.', text)
        return [c.strip() for c in clauses if len(c.strip()) > 20]
    
    def _generate_report(self, risks):
        """ë¦¬ìŠ¤í¬ ë¦¬í¬íŠ¸ ìƒì„±"""
        if not risks:
            return "ìœ„í—˜ ìš”ì†Œê°€ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
        
        report = f"ì´ {len(risks)}ê°œì˜ ìœ„í—˜ ì¡°í•­ì´ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤.\n\n"
        
        for i, risk in enumerate(risks, 1):
            report += f"{i}. ìœ„í—˜ë„: {risk['risk_score']:.2f}\n"
            report += f"   ì¡°í•­: {risk['clause'][:100]}...\n"
            report += f"   ìœ„í—˜ í‚¤ì›Œë“œ: {', '.join(risk['keywords'])}\n\n"
        
        return report

# ì‚¬ìš© ì˜ˆì‹œ
analyzer = ContractRiskAnalyzer()
contract = """
ì œ1ì¡° (ëŒ€ì¶œ ì¡°ê±´)
ë³¸ ê³„ì•½ì˜ ì´ììœ¨ì€ ì—° 15%ì´ë©°, ì—°ì²´ ì‹œ ì—° 25%ì˜ 
ì§€ì—° ì´ìê°€ ë¶€ê³¼ë©ë‹ˆë‹¤. 3ê°œì›” ì´ìƒ ì—°ì²´ ì‹œ 
ë‹´ë³´ë¬¼ì— ëŒ€í•œ ê°•ì œì§‘í–‰ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.
"""

report = analyzer.analyze_contract(contract)
print(report)
```

---

### Project 10: ê·œì œ ì¤€ìˆ˜ ë¶„ì„ ë„êµ¬

```python
"""
ê¸ˆìœµ ê·œì œ ë¬¸ì„œ ìë™ ë¶„ì„
- ê·œì œ ì¡°í•­ vs ë‚´ë¶€ ì •ì±… ë¹„êµ
- ìœ„ë°˜ ê°€ëŠ¥ì„± íƒì§€
- ê°œì„  ê¶Œì¥ì‚¬í•­
"""

class ComplianceAnalyzer:
    def __init__(self):
        self.regulation_db = self._load_regulations()
        self.qa_model = pipeline("question-answering", model="klue/roberta-large")
    
    def check_compliance(self, policy_text, regulation_type="ê¸ˆìœµì†Œë¹„ìë³´í˜¸ë²•"):
        """ì •ì±… ë¬¸ì„œê°€ ê·œì œë¥¼ ì¤€ìˆ˜í•˜ëŠ”ì§€ í™•ì¸"""
        
        # 1. ê´€ë ¨ ê·œì œ ì¡°í•­ ê²€ìƒ‰
        regulations = self.regulation_db[regulation_type]
        
        # 2. ê° ê·œì œ ì¡°í•­ ì²´í¬
        violations = []
        for reg in regulations:
            question = f"{reg['requirement']}ë¥¼ ëª…ì‹œí•˜ê³  ìˆìŠµë‹ˆê¹Œ?"
            
            result = self.qa_model(
                question=question,
                context=policy_text
            )
            
            if result['score'] < 0.5:  # ë‚®ì€ ì‹ ë¢°ë„ = ë¯¸ì¤€ìˆ˜ ê°€ëŠ¥ì„±
                violations.append({
                    'regulation': reg['title'],
                    'requirement': reg['requirement'],
                    'confidence': result['score'],
                    'recommendation': reg['recommendation']
                })
        
        # 3. ë¦¬í¬íŠ¸ ìƒì„±
        return self._generate_compliance_report(violations)
    
    def _load_regulations(self):
        """ê·œì œ DB ë¡œë“œ (ì˜ˆì‹œ)"""
        return {
            "ê¸ˆìœµì†Œë¹„ìë³´í˜¸ë²•": [
                {
                    'title': 'ì œ1ì¡° ì†Œë¹„ì ì •ë³´ ì œê³µ',
                    'requirement': 'ê¸ˆìœµìƒí’ˆì˜ ì£¼ìš” ë‚´ìš©ê³¼ ìœ„í—˜ì‚¬í•­ì„ ëª…í™•íˆ ì„¤ëª…',
                    'recommendation': 'ìƒí’ˆ ì„¤ëª…ì„œì— ìœ„í—˜ ë“±ê¸‰ê³¼ ì£¼ìš” ë‚´ìš©ì„ ì¶”ê°€í•˜ì„¸ìš”'
                },
                {
                    'title': 'ì œ2ì¡° ë¶ˆê³µì • ì˜ì—…í–‰ìœ„ ê¸ˆì§€',
                    'requirement': 'í—ˆìœ„Â·ê³¼ì¥ ì •ë³´ ì œê³µ ê¸ˆì§€',
                    'recommendation': 'ë§ˆì¼€íŒ… ë¬¸êµ¬ì—ì„œ ê³¼ì¥ í‘œí˜„ì„ ì œê±°í•˜ì„¸ìš”'
                }
            ]
        }
    
    def _generate_compliance_report(self, violations):
        if not violations:
            return "âœ… ëª¨ë“  ê·œì œ ì¡°í•­ì„ ì¤€ìˆ˜í•˜ê³  ìˆìŠµë‹ˆë‹¤."
        
        report = f"âš ï¸  {len(violations)}ê°œì˜ ìœ„ë°˜ ê°€ëŠ¥ì„±ì´ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤.\n\n"
        
        for i, v in enumerate(violations, 1):
            report += f"{i}. {v['regulation']}\n"
            report += f"   ìš”êµ¬ì‚¬í•­: {v['requirement']}\n"
            report += f"   ì‹ ë¢°ë„: {v['confidence']:.2f}\n"
            report += f"   ê¶Œì¥ì‚¬í•­: {v['recommendation']}\n\n"
        
        return report
```

---

## âœ… Week 3 ì™„ë£Œ ì²´í¬ë¦¬ìŠ¤íŠ¸

### í”„ë¡œì íŠ¸ ì™„ì„±ë„
- [ ] Multi-task BERT êµ¬í˜„ âœ…
- [ ] ê³„ì•½ì„œ ë¦¬ìŠ¤í¬ ë¶„ì„ âœ…
- [ ] ê·œì œ ì¤€ìˆ˜ ë¶„ì„ ë„êµ¬ âœ…

### ê¸°ìˆ  ìŠµë“
- [ ] Multi-task Learning
- [ ] Domain Adaptation
- [ ] ì‹¤ì „ NLP íŒŒì´í”„ë¼ì¸
- [ ] í”„ë¡œë•ì…˜ ì½”ë“œ ì‘ì„±

### GitHub
- [ ] 3ê°œ ì‹¬í™” í”„ë¡œì íŠ¸ ì»¤ë°‹
- [ ] ìƒì„¸ README ì‘ì„±
- [ ] ì½”ë“œ ë¦¬íŒ©í† ë§ ì™„ë£Œ

### ë‹¤ìŒ ì£¼ ì¤€ë¹„
- [ ] OpenAI API í‚¤ ë°œê¸‰
- [ ] LangChain ê°œë… í•™ìŠµ
- [ ] ChromaDB ì„¤ì¹˜

## ğŸ“Š í•™ìŠµ ì‹œê°„ ê¸°ë¡

| ì¼ì | í™œë™ | ì‹œê°„ | ì™„ë£Œ |
|------|------|------|------|
| Day 15 | Multi-task Learning | 8h | [ ] |
| Day 16 | ë¬¸ì„œ í†µí•© ë¶„ë¥˜ ì‹œìŠ¤í…œ | 8h | [ ] |
| Day 17 | ëª¨ë¸ ìµœì í™” | 8h | [ ] |
| Day 18 | ê³„ì•½ì„œ ë¦¬ìŠ¤í¬ ë¶„ì„ | 8h | [ ] |
| Day 19 | ê·œì œ ì¤€ìˆ˜ ë„êµ¬ (1) | 8h | [ ] |
| Day 20 | ê·œì œ ì¤€ìˆ˜ ë„êµ¬ (2) | 8h | [ ] |
| Day 21 | í†µí•© í…ŒìŠ¤íŠ¸ & ì •ë¦¬ | 8h | [ ] |

---

**Week 3 ì™„ë£Œ í›„ â†’ Week 4 (LangChain + RAG)ë¡œ ì§„í–‰**

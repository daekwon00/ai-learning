{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "c4956079",
      "metadata": {},
      "source": [
        "# ì‹ ìš©í‰ê°€(credit scoring) í”„ë¡œì íŠ¸\n",
        "\n",
        "## í”„ë¡œì íŠ¸ ëª©í‘œ\n",
        "- **ì‹ ìš©ë“±ê¸‰ ì˜ˆì¸¡ ëª¨ë¸**ì„ êµ¬ì¶•í•´ ëŒ€ì¶œ ì‹¬ì‚¬ ì˜ì‚¬ê²°ì •ì„ ì§€ì›í•œë‹¤.\n",
        "- ê¸ˆìœµê¶Œ ì‹¤ë¬´ì—ì„œ ìì£¼ ì‚¬ìš©í•˜ëŠ” **ì´ì§„ ë¶„ë¥˜** ë¬¸ì œë¥¼ ë‹¤ë£¬ë‹¤.\n",
        "\n",
        "## ì‚¬ìš© ì•Œê³ ë¦¬ì¦˜\n",
        "- Logistic Regression\n",
        "- Random Forest\n",
        "- XGBoost\n",
        "\n",
        "## ê¸ˆìœµê¶Œ ì—…ë¬´ ê´€ì \n",
        "- ì‹ ìš©í‰ê°€ëŠ” **ëŒ€ì¶œ ìŠ¹ì¸/í•œë„/ê¸ˆë¦¬ ê²°ì •**ì˜ í•µì‹¬ ê·¼ê±°\n",
        "- ëª¨ë¸ì€ **ì—°ì²´ ê°€ëŠ¥ì„±(ë¶ˆëŸ‰ ìœ„í—˜)**ì„ ì‚¬ì „ì— ì¶”ì •í•´ ë¦¬ìŠ¤í¬ë¥¼ ê´€ë¦¬\n",
        "- í•´ì„ ê°€ëŠ¥í•œ ëª¨ë¸(Logistic)ì€ **ê·œì œ ëŒ€ì‘**ì— ìœ ë¦¬, íŠ¸ë¦¬/ì•™ìƒë¸”ì€ **ì„±ëŠ¥ ê°œì„ **ì— ìœ ë¦¬\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c76cb473",
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# 1. ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n",
        "# =============================================================================\n",
        "# í•™ìŠµ ëª©í‘œ: ì „ì²˜ë¦¬/ëª¨ë¸/í‰ê°€ì— í•„ìš”í•œ ê¸°ë³¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì¤€ë¹„í•œë‹¤\n",
        "# Java ë¹„ìœ : Maven/Gradleë¡œ ì˜ì¡´ì„±ì„ ì¶”ê°€í•˜ê³  import í•˜ëŠ” ë‹¨ê³„ì™€ ìœ ì‚¬\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import (\n",
        "    classification_report,\n",
        "    confusion_matrix,\n",
        "    roc_auc_score,\n",
        ")\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import make_classification\n",
        "\n",
        "# XGBoostëŠ” ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì˜ˆì™¸ ì²˜ë¦¬\n",
        "try:\n",
        "    import xgboost as xgb\n",
        "except ModuleNotFoundError:\n",
        "    xgb = None\n",
        "    print(\"âš ï¸ xgboostê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. (conda install -c conda-forge xgboost)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d9ea939",
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# 2. ìƒ˜í”Œ ë°ì´í„° ë¡œë“œ ë˜ëŠ” ìƒì„±\n",
        "# =============================================================================\n",
        "# í•™ìŠµ ëª©í‘œ: ì‹¤ì œ ë°ì´í„°ê°€ ì—†ì„ ë•Œ ëŒ€ì²´ ë°ì´í„°ë¥¼ ìƒì„±í•´ íë¦„ì„ ê²€ì¦í•œë‹¤\n",
        "# Java ë¹„ìœ : ê°œë°œ ë‹¨ê³„ì—ì„œ Mock ë°ì´í„°ë¥¼ ë§Œë“¤ì–´ ê¸°ëŠ¥ì„ ê²€ì¦í•˜ëŠ” ê²ƒê³¼ ìœ ì‚¬\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "DATA_DIR = Path.cwd() / \"data\"\n",
        "DATA_PATH = DATA_DIR / \"cs-training.csv\"  # Kaggle 'Give Me Some Credit' ì›ë³¸ íŒŒì¼ëª… ì˜ˆì‹œ\n",
        "\n",
        "if DATA_PATH.exists():\n",
        "    try:\n",
        "        # Kaggle ë°ì´í„° ë¡œë“œ (ì˜ˆ: cs-training.csv)\n",
        "        raw_df = pd.read_csv(DATA_PATH)\n",
        "        print(\"âœ… Kaggle ë°ì´í„° ë¡œë“œ ì™„ë£Œ\")\n",
        "    except (FileNotFoundError, pd.errors.EmptyDataError) as e:\n",
        "        print(f\"âŒ ë°ì´í„° ë¡œë“œ ì˜¤ë¥˜: {e}\")\n",
        "        raw_df = None\n",
        "else:\n",
        "    raw_df = None\n",
        "    print(\"âš ï¸ Kaggle ë°ì´í„°ê°€ ì—†ì–´ ìƒ˜í”Œ ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\")\n",
        "\n",
        "# Kaggle ë°ì´í„°ê°€ ì—†ìœ¼ë©´ make_classificationìœ¼ë¡œ ìƒ˜í”Œ ìƒì„±\n",
        "if raw_df is None:\n",
        "    # íŠ¹ì§•: ë‚˜ì´, ì†Œë“, ë¶€ì±„ë¹„ìœ¨, ì—°ì²´ íšŸìˆ˜ ë“±ì„ ê°€ì •\n",
        "    X, y = make_classification(\n",
        "        n_samples=5000,\n",
        "        n_features=6,\n",
        "        n_informative=4,\n",
        "        n_redundant=1,\n",
        "        weights=[0.85, 0.15],\n",
        "        random_state=42,\n",
        "    )\n",
        "\n",
        "    sample_df = pd.DataFrame(\n",
        "        X,\n",
        "        columns=[\n",
        "            \"age\",\n",
        "            \"monthly_income\",\n",
        "            \"debt_ratio\",\n",
        "            \"late_30_59\",\n",
        "            \"late_60_89\",\n",
        "            \"late_90_plus\",\n",
        "        ],\n",
        "    )\n",
        "\n",
        "    # íƒ€ê²Ÿ: Good(0)/Bad(1)ë¡œ ê°€ì •\n",
        "    sample_df[\"target\"] = y\n",
        "    raw_df = sample_df\n",
        "\n",
        "# ë°ì´í„°í”„ë ˆì„ í†µì¼: target ì»¬ëŸ¼ëª… ì •ë¦¬\n",
        "if \"SeriousDlqin2yrs\" in raw_df.columns:\n",
        "    # Kaggle ë°ì´í„°ì˜ íƒ€ê²Ÿ ì»¬ëŸ¼ëª… ì •ë¦¬\n",
        "    raw_df = raw_df.rename(columns={\"SeriousDlqin2yrs\": \"target\"})\n",
        "\n",
        "# íƒ€ê²Ÿì„ Good/Badë¡œ í‘œí˜„í•˜ê¸° ìœ„í•œ ë§¤í•‘\n",
        "raw_df[\"target_label\"] = raw_df[\"target\"].map({0: \"Good\", 1: \"Bad\"})\n",
        "\n",
        "raw_df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4bc409f4",
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# 3. ë°ì´í„° êµ¬ì¡° í™•ì¸\n",
        "# =============================================================================\n",
        "# í•™ìŠµ ëª©í‘œ: ë°ì´í„° í˜•íƒœ/ê²°ì¸¡ì¹˜/ë¶ˆê· í˜• ì—¬ë¶€ë¥¼ íŒŒì•…í•œë‹¤\n",
        "# Java ë¹„ìœ : List<Map>ì˜ size, key íƒ€ì…, null ë¹„ìœ¨ì„ ì ê²€í•˜ëŠ” ë‹¨ê³„ì™€ ìœ ì‚¬\n",
        "\n",
        "print(\"âœ… ë°ì´í„° í¬ê¸° (í–‰, ì—´):\", raw_df.shape)\n",
        "print(\"\\nâœ… ë°ì´í„° íƒ€ì…:\")\n",
        "print(raw_df.dtypes)\n",
        "\n",
        "print(\"\\nâœ… ê²°ì¸¡ì¹˜ í˜„í™©:\")\n",
        "print(raw_df.isnull().sum())\n",
        "\n",
        "print(\"\\nâœ… íƒ€ê²Ÿ ë¶„í¬ (Good/Bad):\")\n",
        "print(raw_df[\"target_label\"].value_counts())\n",
        "\n",
        "print(\"\\nâœ… íƒ€ê²Ÿ ë¹„ìœ¨:\")\n",
        "print(raw_df[\"target_label\"].value_counts(normalize=True).round(4))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9cc602dd",
      "metadata": {},
      "source": [
        "## íƒìƒ‰ì  ë°ì´í„° ë¶„ì„(EDA)\n",
        "\n",
        "### ì‹¤ë¬´ ê´€ì  ìš”ì•½\n",
        "- ê¸ˆìœµê¶Œ ì‹ ìš©í‰ê°€ì—ì„œ **ì†Œë“, ë¶€ì±„ë¹„ìœ¨, ì—°ì²´ íšŸìˆ˜**ëŠ” í•µì‹¬ ìœ„í—˜ ì§€í‘œë¡œ í™œìš©ëœë‹¤.\n",
        "- ì´ìƒì¹˜ëŠ” **ë¶€ì •í™•í•œ ì…ë ¥/ì´ìƒ ê±°ë˜**ë¥¼ ì˜ë¯¸í•  ìˆ˜ ìˆì–´ ë°˜ë“œì‹œ ì ê²€í•œë‹¤.\n",
        "- í´ë˜ìŠ¤ ë¶ˆê· í˜•(ë¶ˆëŸ‰ ë¹„ìœ¨ì´ ë‚®ìŒ)ì€ **ëª¨ë¸ í¸í–¥**ì˜ ì£¼ìš” ì›ì¸ì´ë¯€ë¡œ í™•ì¸ì´ í•„ìˆ˜ë‹¤.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6bcae673",
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# 4. ìˆ˜ì¹˜í˜• ë³€ìˆ˜ ë¶„ì„ (í†µê³„ ìš”ì•½ / ë¶„í¬ / ì´ìƒì¹˜)\n",
        "# =============================================================================\n",
        "# í•™ìŠµ ëª©í‘œ: ìˆ˜ì¹˜í˜• ë³€ìˆ˜ì˜ ë¶„í¬ì™€ ì´ìƒì¹˜ë¥¼ íŒŒì•…í•œë‹¤\n",
        "# Java ë¹„ìœ : ìˆ«ìí˜• í•„ë“œì˜ ê¸°ë³¸ í†µê³„ì™€ ì´ìƒê°’ ê²€ì¦ ë¡œì§ê³¼ ìœ ì‚¬\n",
        "\n",
        "numeric_cols = raw_df.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
        "if \"target\" in numeric_cols:\n",
        "    numeric_cols.remove(\"target\")\n",
        "\n",
        "print(\"âœ… ìˆ˜ì¹˜í˜• ë³€ìˆ˜ ëª©ë¡:\", numeric_cols)\n",
        "\n",
        "# describe() í†µê³„ ìš”ì•½\n",
        "print(\"\\nâœ… ìˆ˜ì¹˜í˜• ë³€ìˆ˜ í†µê³„ ìš”ì•½\")\n",
        "print(raw_df[numeric_cols].describe())\n",
        "\n",
        "# íˆìŠ¤í† ê·¸ë¨ (ë¶„í¬ í™•ì¸)\n",
        "raw_df[numeric_cols].hist(bins=30, figsize=(12, 8))\n",
        "plt.suptitle(\"ìˆ˜ì¹˜í˜• ë³€ìˆ˜ ë¶„í¬ (íˆìŠ¤í† ê·¸ë¨)\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# ë°•ìŠ¤í”Œë¡¯ (ì´ìƒì¹˜ íƒì§€)\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.boxplot(data=raw_df[numeric_cols])\n",
        "plt.title(\"ìˆ˜ì¹˜í˜• ë³€ìˆ˜ ì´ìƒì¹˜ ë¶„í¬ (ë°•ìŠ¤í”Œë¡¯)\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.grid(alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86e91c03",
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# 5. ë²”ì£¼í˜• ë³€ìˆ˜ ë¶„ì„\n",
        "# =============================================================================\n",
        "# í•™ìŠµ ëª©í‘œ: ë²”ì£¼í˜• ë³€ìˆ˜ì˜ ë¶„í¬ë¥¼ íŒŒì•…í•œë‹¤\n",
        "# Java ë¹„ìœ : enum/ë¬¸ìì—´ ê°’ì˜ ë¹ˆë„ë¥¼ ì§‘ê³„í•˜ëŠ” ë‹¨ê³„ì™€ ìœ ì‚¬\n",
        "\n",
        "categorical_cols = raw_df.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
        "\n",
        "if not categorical_cols:\n",
        "    print(\"âš ï¸ ë²”ì£¼í˜• ë³€ìˆ˜ê°€ ì—†ìŠµë‹ˆë‹¤. (ìƒ˜í”Œ ë°ì´í„° ê¸°ì¤€)\")\n",
        "else:\n",
        "    print(\"âœ… ë²”ì£¼í˜• ë³€ìˆ˜ ëª©ë¡:\", categorical_cols)\n",
        "    for col in categorical_cols:\n",
        "        print(f\"\\nâœ… {col} ê°’ ë¶„í¬\")\n",
        "        print(raw_df[col].value_counts())\n",
        "\n",
        "        plt.figure(figsize=(8, 4))\n",
        "        sns.countplot(data=raw_df, x=col)\n",
        "        plt.title(f\"{col} ë¶„í¬\")\n",
        "        plt.xticks(rotation=45)\n",
        "        plt.grid(alpha=0.3)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b42ee20c",
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# 6. íƒ€ê²Ÿ ë³€ìˆ˜ ë¶„ì„ (Good/Bad ë¹„ìœ¨)\n",
        "# =============================================================================\n",
        "# í•™ìŠµ ëª©í‘œ: í´ë˜ìŠ¤ ë¶ˆê· í˜• ì—¬ë¶€ë¥¼ í™•ì¸í•œë‹¤\n",
        "# Java ë¹„ìœ : ì •ìƒ/ì´ìƒ ì¼€ì´ìŠ¤ì˜ ë¹„ìœ¨ì„ ì ê²€í•˜ëŠ” ë‹¨ê³„ì™€ ìœ ì‚¬\n",
        "\n",
        "# Good/Bad ë¹„ìœ¨\n",
        "target_counts = raw_df[\"target_label\"].value_counts()\n",
        "print(\"âœ… íƒ€ê²Ÿ ë¶„í¬:\")\n",
        "print(target_counts)\n",
        "\n",
        "plt.figure(figsize=(5, 4))\n",
        "sns.countplot(data=raw_df, x=\"target_label\")\n",
        "plt.title(\"íƒ€ê²Ÿ ë¶„í¬ (Good/Bad)\")\n",
        "plt.grid(alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "imbalance_ratio = (target_counts.min() / target_counts.max()) if target_counts.max() > 0 else 0\n",
        "print(f\"âœ… í´ë˜ìŠ¤ ë¶ˆê· í˜• ë¹„ìœ¨(ì†Œìˆ˜/ë‹¤ìˆ˜): {imbalance_ratio:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18aa311b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# 7. ë³€ìˆ˜ ê°„ ê´€ê³„ ë¶„ì„\n",
        "# =============================================================================\n",
        "# í•™ìŠµ ëª©í‘œ: ìƒê´€ê´€ê³„ì™€ íƒ€ê²Ÿë³„ ë¶„í¬ ì°¨ì´ë¥¼ í™•ì¸í•œë‹¤\n",
        "# Java ë¹„ìœ : ì—¬ëŸ¬ í•„ë“œ ê°„ ìƒê´€/ì˜ì¡´ì„±ì„ í™•ì¸í•˜ëŠ” í†µê³„ ë¶„ì„ ë‹¨ê³„\n",
        "\n",
        "# ìˆ˜ì¹˜í˜• ë³€ìˆ˜ ìƒê´€ê´€ê³„ íˆíŠ¸ë§µ\n",
        "plt.figure(figsize=(8, 6))\n",
        "correlation = raw_df[numeric_cols + [\"target\"]].corr()\n",
        "sns.heatmap(correlation, annot=True, cmap=\"coolwarm\", vmin=-1, vmax=1)\n",
        "plt.title(\"ìˆ˜ì¹˜í˜• ë³€ìˆ˜ ìƒê´€ê´€ê³„ íˆíŠ¸ë§µ\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# íƒ€ê²Ÿë³„ ë³€ìˆ˜ ë¶„í¬ ë¹„êµ (violinplot, boxplot)\n",
        "if numeric_cols:\n",
        "    selected_cols = numeric_cols[:3]  # ì£¼ìš” ë³€ìˆ˜ 3ê°œë§Œ ì„ íƒ\n",
        "    for col in selected_cols:\n",
        "        plt.figure(figsize=(6, 4))\n",
        "        sns.violinplot(data=raw_df, x=\"target_label\", y=col)\n",
        "        plt.title(f\"íƒ€ê²Ÿë³„ {col} ë¶„í¬ (Violin)\")\n",
        "        plt.grid(alpha=0.3)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        plt.figure(figsize=(6, 4))\n",
        "        sns.boxplot(data=raw_df, x=\"target_label\", y=col)\n",
        "        plt.title(f\"íƒ€ê²Ÿë³„ {col} ë¶„í¬ (Boxplot)\")\n",
        "        plt.grid(alpha=0.3)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "# í˜ì–´í”Œë¡¯ (ì£¼ìš” ë³€ìˆ˜ë§Œ)\n",
        "if numeric_cols:\n",
        "    pair_cols = numeric_cols[:4] + [\"target_label\"]\n",
        "    sns.pairplot(raw_df[pair_cols], hue=\"target_label\", corner=True)\n",
        "    plt.suptitle(\"ì£¼ìš” ë³€ìˆ˜ í˜ì–´í”Œë¡¯\", y=1.02)\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "25f15132",
      "metadata": {},
      "source": [
        "## ì¸ì‚¬ì´íŠ¸ ì •ë¦¬ (ì´ˆì•ˆ)\n",
        "\n",
        "### ì‹ ìš©ë“±ê¸‰ì— ì˜í–¥ì„ ë¯¸ì¹  ê°€ëŠ¥ì„±ì´ ë†’ì€ ë³€ìˆ˜\n",
        "- **ì—°ì²´ íšŸìˆ˜ ê³„ì—´ ë³€ìˆ˜**: ê³¼ê±° ì—°ì²´ ì´ë ¥ì€ ì‹ ìš© ìœ„í—˜ì˜ ì§ì ‘ ì§€í‘œ\n",
        "- **ë¶€ì±„ë¹„ìœ¨/ì†Œë“**: ìƒí™˜ ì—¬ë ¥ì˜ í•µì‹¬ ì§€í‘œ\n",
        "- **ë‚˜ì´/ì—°ì²´ íŒ¨í„´**: ìœ„í—˜êµ° ë¶„ë¦¬ì—ì„œ ìœ ì˜ë¯¸í•  ìˆ˜ ìˆìŒ\n",
        "\n",
        "### ì´ìƒì¹˜ ì²˜ë¦¬ê°€ í•„ìš”í•œ ê°€ëŠ¥ì„±ì´ ë†’ì€ ë³€ìˆ˜\n",
        "- **ì›” ì†Œë“, ë¶€ì±„ë¹„ìœ¨**: ê·¹ë‹¨ê°’ì´ ë§ì„ ê²½ìš° ëª¨ë¸ ì™œê³¡ ê°€ëŠ¥\n",
        "- **ì—°ì²´ íšŸìˆ˜**: ë¹„ì •ìƒì ìœ¼ë¡œ í° ê°’ì€ ì…ë ¥ ì˜¤ë¥˜ ë˜ëŠ” íŠ¹ì´ ì¼€ì´ìŠ¤ ê°€ëŠ¥\n",
        "\n",
        "### íŒŒìƒ ë³€ìˆ˜ í•„ìš”ì„±\n",
        "- **ì†Œë“ ëŒ€ë¹„ ë¶€ì±„ ê·œëª¨(ë¹„ìœ¨)**, **ì—°ì²´ ê°€ì¤‘í•©** ë“± íŒŒìƒ ë³€ìˆ˜ê°€ ë¦¬ìŠ¤í¬ ì„¤ëª…ë ¥ì„ ë†’ì¼ ìˆ˜ ìˆìŒ\n",
        "- ê·œì œ ë³´ê³ ë¥¼ ê³ ë ¤í•˜ë©´ **í•´ì„ ê°€ëŠ¥í•œ íŒŒìƒ ë³€ìˆ˜**ê°€ ìœ ë¦¬\n",
        "\n",
        "### ê¸ˆìœµê¶Œ ì‹¤ë¬´ ë¹„êµ\n",
        "- ì‹¤ì œ ì‹ ìš©í‰ê°€ì—ì„œëŠ” **ì—°ì²´ ì´ë ¥ + ì†Œë“ ì•ˆì •ì„± + ë¶€ì±„ë¹„ìœ¨**ì„ ê°€ì¥ ì¤‘ìš”í•˜ê²Œ ë³¸ë‹¤.\n",
        "- ëª¨ë¸ ì„±ëŠ¥ë¿ ì•„ë‹ˆë¼ **ê·œì œ/ê°ì‚¬ ëŒ€ì‘ ê°€ëŠ¥ì„±**(ì„¤ëª…ë ¥)ì´ í•„ìˆ˜ ìš”ê±´ì´ë‹¤.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe4989c4",
      "metadata": {},
      "source": [
        "## ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ êµ¬ì¶• (sklearn Pipeline)\n",
        "\n",
        "### í•™ìŠµ í¬ì¸íŠ¸\n",
        "- **Pipeline ì¥ì **: ì „ì²˜ë¦¬+ëª¨ë¸ì„ í•˜ë‚˜ë¡œ ë¬¶ì–´ **ì¬ì‚¬ìš©ì„±**ê³¼ **ë°ì´í„° ìœ ì¶œ ë°©ì§€**ë¥¼ í™•ë³´\n",
        "- **fit_transform vs transform**\n",
        "  - `fit_transform`: í•™ìŠµ ë°ì´í„°ë¡œ í†µê³„(í‰ê· /ì¤‘ì•™ê°’ ë“±) ê³„ì‚° + ë³€í™˜\n",
        "  - `transform`: ì´ë¯¸ ê³„ì‚°ëœ í†µê³„ë¥¼ ì ìš©í•´ ë³€í™˜ë§Œ ìˆ˜í–‰\n",
        "- **Java Builder íŒ¨í„´ ë¹„êµ**: ë‹¨ê³„ë³„ ì„¤ì •ì„ ì²´ì´ë‹í•´ í•˜ë‚˜ì˜ ê°ì²´(íŒŒì´í”„ë¼ì¸)ë¥¼ êµ¬ì„±í•˜ëŠ” ë°©ì‹ê³¼ ìœ ì‚¬\n",
        "\n",
        "### ìŠ¤ì¼€ì¼ë§ ì„ íƒ (ê¸ˆìœµ ë°ì´í„° ê´€ì )\n",
        "- **MinMaxScaler**: ì´ìƒì¹˜(outlier)ì— ë¯¼ê° â†’ ê·¹ë‹¨ê°’ì´ ìˆìœ¼ë©´ ìŠ¤ì¼€ì¼ì´ ì™œê³¡ë  ìˆ˜ ìˆìŒ\n",
        "- **StandardScaler**: í‰ê· /í‘œì¤€í¸ì°¨ ê¸°ë°˜ â†’ ê¸ˆìœµ ë°ì´í„°ì˜ ë¶„í¬ ì•ˆì •í™”ì— ë” ì í•©í•œ ê²½ìš°ê°€ ë§ìŒ\n",
        "- ê¸°ë³¸ ì„ íƒì€ **StandardScaler**, í•„ìš” ì‹œ ì˜µì…˜ìœ¼ë¡œ MinMaxë¥¼ ì‚¬ìš©\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce684fbc",
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# 8. ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ í•¨ìˆ˜ (ê²°ì¸¡ì¹˜/ìŠ¤ì¼€ì¼ë§/ì¸ì½”ë”©)\n",
        "# =============================================================================\n",
        "# í•™ìŠµ ëª©í‘œ: ColumnTransformer + Pipelineìœ¼ë¡œ ì „ì²˜ë¦¬ íë¦„ì„ ìº¡ìŠí™”í•œë‹¤\n",
        "# Java ë¹„ìœ : Builder íŒ¨í„´ìœ¼ë¡œ ì „ì²˜ë¦¬ ëª¨ë“ˆì„ ì¡°ë¦½í•˜ëŠ” ë°©ì‹ê³¼ ìœ ì‚¬\n",
        "\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
        "\n",
        "\n",
        "def build_preprocess_pipeline(\n",
        "    df: pd.DataFrame,\n",
        "    target_col: str = \"target\",\n",
        "    scaler_type: str = \"standard\",\n",
        ") -> tuple[Pipeline, pd.DataFrame, pd.Series, list[str], list[str]]:\n",
        "    \"\"\"\n",
        "    ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ì„ êµ¬ì„±í•˜ê³  í•™ìŠµ ë°ì´í„°ë¥¼ ë¶„ë¦¬í•œë‹¤.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): ì›ë³¸ ë°ì´í„°í”„ë ˆì„\n",
        "        target_col (str): íƒ€ê²Ÿ ì»¬ëŸ¼ëª…\n",
        "        scaler_type (str): 'standard' ë˜ëŠ” 'minmax'\n",
        "\n",
        "    Returns:\n",
        "        tuple: (preprocess_pipeline, X_train, X_test, y_train, y_test) ë°˜í™˜\n",
        "    \"\"\"\n",
        "    # ìˆ˜ì¹˜í˜•/ë²”ì£¼í˜• ì»¬ëŸ¼ ë¶„ë¦¬\n",
        "    numeric_features = df.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
        "    categorical_features = df.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
        "\n",
        "    if target_col in numeric_features:\n",
        "        numeric_features.remove(target_col)\n",
        "\n",
        "    if \"target_label\" in categorical_features:\n",
        "        categorical_features.remove(\"target_label\")\n",
        "\n",
        "    # ìŠ¤ì¼€ì¼ëŸ¬ ì„ íƒ (ê¸ˆìœµ ë°ì´í„°ëŠ” StandardScalerê°€ ì¼ë°˜ì ìœ¼ë¡œ ì•ˆì •ì )\n",
        "    if scaler_type == \"minmax\":\n",
        "        scaler = MinMaxScaler()\n",
        "    else:\n",
        "        scaler = StandardScaler()\n",
        "\n",
        "    # ìˆ˜ì¹˜í˜• íŒŒì´í”„ë¼ì¸: ê²°ì¸¡ì¹˜ -> ìŠ¤ì¼€ì¼ë§\n",
        "    numeric_pipeline = Pipeline(\n",
        "        steps=[\n",
        "            (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
        "            (\"scaler\", scaler),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    # ë²”ì£¼í˜• íŒŒì´í”„ë¼ì¸: ê²°ì¸¡ì¹˜ -> ì›í•« ì¸ì½”ë”©\n",
        "    categorical_pipeline = Pipeline(\n",
        "        steps=[\n",
        "            (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "            (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    # ColumnTransformerë¡œ í†µí•©\n",
        "    preprocess = ColumnTransformer(\n",
        "        transformers=[\n",
        "            (\"num\", numeric_pipeline, numeric_features),\n",
        "            (\"cat\", categorical_pipeline, categorical_features),\n",
        "        ],\n",
        "        remainder=\"drop\",\n",
        "        sparse_threshold=0.3,  # í¬ì†Œ í–‰ë ¬ ë¹„ìœ¨ ê¸°ì¤€\n",
        "    )\n",
        "\n",
        "    # ì…ë ¥/íƒ€ê²Ÿ ë¶„ë¦¬\n",
        "    X = df.drop(columns=[target_col])\n",
        "    y = df[target_col]\n",
        "\n",
        "    # ë°ì´í„° ë¶„í•  (80:20, í´ë˜ìŠ¤ ë¹„ìœ¨ ìœ ì§€)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X,\n",
        "        y,\n",
        "        test_size=0.2,\n",
        "        stratify=y,\n",
        "        random_state=42,\n",
        "    )\n",
        "\n",
        "    # ìµœì¢… íŒŒì´í”„ë¼ì¸ (ì „ì²˜ë¦¬ë§Œ í¬í•¨)\n",
        "    preprocess_pipeline = Pipeline(\n",
        "        steps=[\n",
        "            (\"preprocess\", preprocess),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    print(\"âœ… ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ êµ¬ì„± ì™„ë£Œ\")\n",
        "    print(\"- ìˆ˜ì¹˜í˜• ì»¬ëŸ¼:\", numeric_features)\n",
        "    print(\"- ë²”ì£¼í˜• ì»¬ëŸ¼:\", categorical_features)\n",
        "    print(\"- ìŠ¤ì¼€ì¼ëŸ¬:\", scaler.__class__.__name__)\n",
        "\n",
        "    return preprocess_pipeline, X_train, X_test, y_train, y_test\n",
        "\n",
        "\n",
        "# íŒŒì´í”„ë¼ì¸ ìƒì„± ì˜ˆì‹œ\n",
        "preprocess_pipeline, X_train, X_test, y_train, y_test = build_preprocess_pipeline(\n",
        "    raw_df,\n",
        "    target_col=\"target\",\n",
        "    scaler_type=\"standard\",\n",
        ")\n",
        "\n",
        "# fit_transform vs transform ì°¨ì´ ë°ëª¨\n",
        "X_train_prepared = preprocess_pipeline.fit_transform(X_train)\n",
        "X_test_prepared = preprocess_pipeline.transform(X_test)\n",
        "\n",
        "print(\"âœ… ì „ì²˜ë¦¬ ì™„ë£Œ (í›ˆë ¨/í…ŒìŠ¤íŠ¸)\")\n",
        "print(\"- X_train_prepared íƒ€ì…:\", type(X_train_prepared))\n",
        "print(\"- X_test_prepared íƒ€ì…:\", type(X_test_prepared))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "91ea78f2",
      "metadata": {},
      "source": [
        "## ëª¨ë¸ í•™ìŠµ ë° ë¹„êµ (Baseline vs Ensemble)\n",
        "\n",
        "### ì‹¤ë¬´ ê³ ë ¤ì‚¬í•­\n",
        "- **ì‹ ìš©í‰ê°€ì—ì„œëŠ” Recall(ë¯¸íƒ ë°©ì§€)ì´ ë” ì¤‘ìš”í•œ ê²½ìš°ê°€ ë§ë‹¤.**\n",
        "  - Badë¥¼ Goodìœ¼ë¡œ ì˜ëª» ë¶„ë¥˜í•˜ë©´ **ë¶€ì‹¤ ëŒ€ì¶œ**ë¡œ ì§ê²°\n",
        "- **Precisionë„ ì¤‘ìš”**\n",
        "  - Good ê³ ê°ì„ Badë¡œ ì˜¤íŒí•˜ë©´ **ìš°ëŸ‰ ê³ ê° ì´íƒˆ**ê³¼ ê¸°íšŒ ì†ì‹¤\n",
        "- **False Negative(ë¯¸íƒ)**: ë¶€ì‹¤ ë°œìƒ â†’ ì†ì‹¤/ëŒ€ì†ì¶©ë‹¹ê¸ˆ ì¦ê°€\n",
        "- **False Positive(ì˜¤íƒ)**: ê³ ê° ì´íƒˆ â†’ ìˆ˜ìµ ê¸°íšŒ ì†ì‹¤\n",
        "- **ê·œì œ ê´€ì **: í•´ì„ ê°€ëŠ¥ì„±(Logistic) + ì„±ëŠ¥(RandomForest/XGBoost) ê· í˜• í•„ìš”\n",
        "\n",
        "### ëª¨ë¸ íŠ¹ì§• ìš”ì•½\n",
        "- **Logistic Regression**: í•´ì„ ìš©ì´, ê·œì œ ëŒ€ì‘ì— ìœ ë¦¬, ì„±ëŠ¥ì€ ì œí•œì \n",
        "- **Random Forest**: ë¹„ì„ í˜• íŒ¨í„´ í•™ìŠµ, ë³€ìˆ˜ ì¤‘ìš”ë„ í•´ì„ ê°€ëŠ¥, í•™ìŠµ ì‹œê°„ ì¦ê°€\n",
        "- **XGBoost**: ì„±ëŠ¥ ê°•ì , í•˜ì´í¼íŒŒë¼ë¯¸í„° ë¯¼ê°, ê·œì œ/ì„¤ëª…ë ¥ ë³´ì™„ í•„ìš”\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb61d8d9",
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# 9. ëª¨ë¸ í•™ìŠµ ë° í‰ê°€ ìœ í‹¸ë¦¬í‹°\n",
        "# =============================================================================\n",
        "# í•™ìŠµ ëª©í‘œ: ì—¬ëŸ¬ ëª¨ë¸ì„ ë™ì¼ ê¸°ì¤€ìœ¼ë¡œ í•™ìŠµ/í‰ê°€í•œë‹¤\n",
        "# Java ë¹„ìœ : ê³µí†µ ì¸í„°í˜ì´ìŠ¤ë¡œ êµ¬í˜„ì²´ë¥¼ êµì²´í•˜ë©° ì„±ëŠ¥ ë¹„êµí•˜ëŠ” ë°©ì‹ê³¼ ìœ ì‚¬\n",
        "\n",
        "import time\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    roc_auc_score,\n",
        "    roc_curve,\n",
        ")\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "\n",
        "def evaluate_model(name: str, model_pipeline: Pipeline, X_train, X_test, y_train, y_test) -> dict:\n",
        "    \"\"\"\n",
        "    ëª¨ë¸ í•™ìŠµ í›„ ì£¼ìš” ì§€í‘œë¥¼ ê³„ì‚°í•˜ê³  ROC/Confusion Matrixë¥¼ ì¶œë ¥í•œë‹¤.\n",
        "    \"\"\"\n",
        "    start_time = time.time()\n",
        "    model_pipeline.fit(X_train, y_train)\n",
        "    train_time = time.time() - start_time\n",
        "\n",
        "    y_pred = model_pipeline.predict(X_test)\n",
        "\n",
        "    # ROC-AUC ê³„ì‚°ì„ ìœ„í•´ í™•ë¥  ì˜ˆì¸¡ í•„ìš”\n",
        "    if hasattr(model_pipeline, \"predict_proba\"):\n",
        "        y_proba = model_pipeline.predict_proba(X_test)[:, 1]\n",
        "    else:\n",
        "        y_proba = None\n",
        "\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    auc_score = roc_auc_score(y_test, y_proba) if y_proba is not None else np.nan\n",
        "\n",
        "    print(f\"\\nâœ… {name} í‰ê°€ ê²°ê³¼\")\n",
        "    print(f\"- Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"- Precision: {precision:.4f}\")\n",
        "    print(f\"- Recall: {recall:.4f}\")\n",
        "    print(f\"- F1-Score: {f1:.4f}\")\n",
        "    print(f\"- ROC-AUC: {auc_score:.4f}\")\n",
        "    print(f\"- í•™ìŠµ ì‹œê°„: {train_time:.2f}ì´ˆ\")\n",
        "\n",
        "    # Confusion Matrix ì‹œê°í™”\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    plt.figure(figsize=(4, 3))\n",
        "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "    plt.title(f\"{name} Confusion Matrix\")\n",
        "    plt.xlabel(\"Predicted\")\n",
        "    plt.ylabel(\"Actual\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # ROC Curve\n",
        "    if y_proba is not None:\n",
        "        fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
        "        plt.figure(figsize=(5, 4))\n",
        "        plt.plot(fpr, tpr, label=f\"AUC={auc_score:.3f}\")\n",
        "        plt.plot([0, 1], [0, 1], linestyle=\"--\", color=\"gray\")\n",
        "        plt.title(f\"{name} ROC Curve\")\n",
        "        plt.xlabel(\"False Positive Rate\")\n",
        "        plt.ylabel(\"True Positive Rate\")\n",
        "        plt.legend(loc=\"lower right\")\n",
        "        plt.grid(alpha=0.3)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    # Classification Report\n",
        "    print(\"\\nğŸ“Œ Classification Report\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "    return {\n",
        "        \"model\": name,\n",
        "        \"accuracy\": accuracy,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"f1\": f1,\n",
        "        \"auc\": auc_score,\n",
        "        \"train_time_sec\": train_time,\n",
        "    }\n",
        "\n",
        "\n",
        "def cross_validate_model(name: str, model_pipeline: Pipeline, X, y) -> dict:\n",
        "    \"\"\"\n",
        "    StratifiedKFold 5-fold êµì°¨ ê²€ì¦ ìˆ˜í–‰\n",
        "    \"\"\"\n",
        "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "    scores = {\"accuracy\": [], \"precision\": [], \"recall\": [], \"f1\": [], \"auc\": []}\n",
        "\n",
        "    for fold, (train_idx, test_idx) in enumerate(skf.split(X, y), start=1):\n",
        "        X_train_cv, X_test_cv = X.iloc[train_idx], X.iloc[test_idx]\n",
        "        y_train_cv, y_test_cv = y.iloc[train_idx], y.iloc[test_idx]\n",
        "\n",
        "        model_pipeline.fit(X_train_cv, y_train_cv)\n",
        "        y_pred_cv = model_pipeline.predict(X_test_cv)\n",
        "\n",
        "        if hasattr(model_pipeline, \"predict_proba\"):\n",
        "            y_proba_cv = model_pipeline.predict_proba(X_test_cv)[:, 1]\n",
        "        else:\n",
        "            y_proba_cv = None\n",
        "\n",
        "        scores[\"accuracy\"].append(accuracy_score(y_test_cv, y_pred_cv))\n",
        "        scores[\"precision\"].append(precision_score(y_test_cv, y_pred_cv))\n",
        "        scores[\"recall\"].append(recall_score(y_test_cv, y_pred_cv))\n",
        "        scores[\"f1\"].append(f1_score(y_test_cv, y_pred_cv))\n",
        "        scores[\"auc\"].append(roc_auc_score(y_test_cv, y_proba_cv) if y_proba_cv is not None else np.nan)\n",
        "\n",
        "        print(f\"âœ… {name} Fold {fold} ì™„ë£Œ\")\n",
        "\n",
        "    # í‰ê· /í‘œì¤€í¸ì°¨ ìš”ì•½\n",
        "    summary = {metric: (np.mean(values), np.std(values)) for metric, values in scores.items()}\n",
        "    print(f\"\\nğŸ“Œ {name} êµì°¨ ê²€ì¦ í‰ê· /í‘œì¤€í¸ì°¨\")\n",
        "    for metric, (mean_val, std_val) in summary.items():\n",
        "        print(f\"- {metric}: {mean_val:.4f} Â± {std_val:.4f}\")\n",
        "\n",
        "    return summary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86b5e2ca",
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# 10. ëª¨ë¸ í•™ìŠµ ë° ë¹„êµ ì‹¤í–‰\n",
        "# =============================================================================\n",
        "# í•™ìŠµ ëª©í‘œ: baselineê³¼ ì•™ìƒë¸” ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ë¹„êµí•œë‹¤\n",
        "# Java ë¹„ìœ : ì—¬ëŸ¬ êµ¬í˜„ì²´ë¥¼ ê°™ì€ ì¸í„°í˜ì´ìŠ¤ë¡œ í‰ê°€í•˜ëŠ” ë°©ì‹ê³¼ ìœ ì‚¬\n",
        "\n",
        "# ëª¨ë¸ ì •ì˜\n",
        "logistic_model = LogisticRegression(max_iter=1000)\n",
        "rf_model = RandomForestClassifier(n_estimators=200, random_state=42)\n",
        "\n",
        "models = {\n",
        "    \"Logistic Regression\": logistic_model,\n",
        "    \"Random Forest\": rf_model,\n",
        "}\n",
        "\n",
        "# XGBoostëŠ” ì„¤ì¹˜ëœ ê²½ìš°ë§Œ ì¶”ê°€\n",
        "if xgb is not None:\n",
        "    xgb_model = xgb.XGBClassifier(\n",
        "        n_estimators=200,\n",
        "        max_depth=4,\n",
        "        learning_rate=0.1,\n",
        "        subsample=0.8,\n",
        "        colsample_bytree=0.8,\n",
        "        eval_metric=\"logloss\",\n",
        "        random_state=42,\n",
        "    )\n",
        "    models[\"XGBoost\"] = xgb_model\n",
        "else:\n",
        "    print(\"âš ï¸ XGBoost ëª¨ë¸ì€ ì„¤ì¹˜ë˜ì§€ ì•Šì•„ ìŠ¤í‚µí•©ë‹ˆë‹¤.\")\n",
        "\n",
        "# ê³µí†µ ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì¬ì‚¬ìš©\n",
        "results = []\n",
        "cv_results = {}\n",
        "\n",
        "for name, model in models.items():\n",
        "    full_pipeline = Pipeline(\n",
        "        steps=[\n",
        "            (\"preprocess\", preprocess_pipeline.named_steps[\"preprocess\"]),\n",
        "            (\"model\", model),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    # ëª¨ë¸ í‰ê°€\n",
        "    result = evaluate_model(name, full_pipeline, X_train, X_test, y_train, y_test)\n",
        "    results.append(result)\n",
        "\n",
        "    # êµì°¨ ê²€ì¦\n",
        "    cv_summary = cross_validate_model(name, full_pipeline, X_train, y_train)\n",
        "    cv_results[name] = cv_summary\n",
        "\n",
        "# ëª¨ë¸ ë¹„êµ í…Œì´ë¸”\n",
        "results_df = pd.DataFrame(results)\n",
        "print(\"\\nâœ… ëª¨ë¸ ë¹„êµ í…Œì´ë¸”\")\n",
        "print(results_df)\n",
        "\n",
        "# ì„±ëŠ¥ ê¸°ì¤€: AUC ìš°ì„ , ê·¸ë‹¤ìŒ F1\n",
        "results_df_sorted = results_df.sort_values(by=[\"auc\", \"f1\"], ascending=False)\n",
        "print(\"\\nâœ… ì„±ëŠ¥ ìš°ìˆ˜ ëª¨ë¸ (AUC, F1 ê¸°ì¤€)\")\n",
        "print(results_df_sorted[[\"model\", \"auc\", \"f1\", \"precision\", \"recall\"]])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "65adf351",
      "metadata": {},
      "source": [
        "## í‰ê°€ ì§€í‘œ í•´ì„ (ê¸ˆìœµ ì‹¤ë¬´ ê´€ì )\n",
        "\n",
        "- **Accuracy**: ì „ì²´ ë§ì¶˜ ë¹„ìœ¨, ë¶ˆê· í˜• ë°ì´í„°ì—ì„œëŠ” ê³¼ëŒ€í‰ê°€ ìœ„í—˜\n",
        "- **Precision**: Badë¡œ ì˜ˆì¸¡í•œ ê²ƒ ì¤‘ ì‹¤ì œ Bad ë¹„ìœ¨ â†’ ë¶ˆí•„ìš”í•œ ê±°ì ˆ ìµœì†Œí™”ì— ì¤‘ìš”\n",
        "- **Recall**: ì‹¤ì œ Bad ì¤‘ Badë¡œ ì¡ì•„ë‚¸ ë¹„ìœ¨ â†’ ë¶€ì‹¤ ëŒ€ì¶œ ë°©ì§€ì— í•µì‹¬\n",
        "- **F1-Score**: Precision/Recall ê· í˜• ì§€í‘œ â†’ ë¦¬ìŠ¤í¬/ìˆ˜ìµ ê· í˜• íŒë‹¨\n",
        "- **ROC-AUC**: ì„ê³„ê°’ì— ë…ë¦½ì ì¸ ë¶„ë¥˜ ì„±ëŠ¥ â†’ ëª¨ë¸ ë¹„êµì— ìœ ìš©\n",
        "\n",
        "### ì–´ë–¤ ì§€í‘œê°€ ë” ì¤‘ìš”í•œê°€?\n",
        "- **ë¦¬ìŠ¤í¬ ìµœì†Œí™” ê´€ì **: Recall ìš°ì„  (ë¶€ì‹¤ ëŒ€ì¶œ ë°©ì§€)\n",
        "- **ìš°ëŸ‰ ê³ ê° í™•ë³´ ê´€ì **: Precisionë„ ì¤‘ìš” (ê³¼ë„í•œ ê±°ì ˆ ë°©ì§€)\n",
        "\n",
        "### ê·œì œ/ê°ì‚¬ ê´€ì  ëª¨ë¸ ì„ íƒ ê¸°ì¤€\n",
        "- **ì„¤ëª… ê°€ëŠ¥ì„±**: Logistic Regression ìš°ìœ„\n",
        "- **ì„±ëŠ¥ ì¤‘ì‹¬**: XGBoost/RandomForest ìš°ìœ„\n",
        "- **ì‹¤ë¬´ ê· í˜•**: ì„±ëŠ¥ + ì„¤ëª…ë ¥ + ì•ˆì •ì„±ì˜ ê· í˜•ì´ í•µì‹¬\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d9f2ac7",
      "metadata": {},
      "source": [
        "## ëª¨ë¸ ìµœì í™” ë° í•´ì„ (ë°°í¬ ê´€ì  í¬í•¨)\n",
        "\n",
        "### ì‹¤ë¬´ í™œìš©\n",
        "- **Feature Importance**ëŠ” ì‹ ìš©ì •ì±…ì˜ ìš°ì„ ìˆœìœ„(ì˜ˆ: ì—°ì²´ ì´ë ¥, ë¶€ì±„ë¹„ìœ¨ ê¸°ì¤€)ë¥¼ ì„¤ê³„í•  ë•Œ ì°¸ê³  ì§€í‘œë¡œ í™œìš©\n",
        "- ì¤‘ìš” ë³€ìˆ˜ê°€ ì •ì±…ê³¼ ì¶©ëŒí•  ê²½ìš°, **ê·œì œ/ê°ì‚¬ ëŒ€ì‘ ê°€ëŠ¥ì„±**ì„ ìœ„í•´ í•´ì„ ê°€ëŠ¥í•œ ê¸°ì¤€ìœ¼ë¡œ ì¬ì •ì˜ í•„ìš”\n",
        "\n",
        "### ê¸ˆìœµ ê·œì œ ê´€ì \n",
        "- ëª¨ë¸ ì„±ëŠ¥ë§Œí¼ **ì„¤ëª… ê°€ëŠ¥ì„±(í•´ì„ë ¥)**ì´ ì¤‘ìš”\n",
        "- ê·œì œê¸°ê´€ì€ â€œì™œ ì´ ê³ ê°ì´ ê±°ì ˆë˜ì—ˆëŠ”ê°€?â€ë¥¼ ì„¤ëª…í•  ìˆ˜ ìˆì–´ì•¼ í•¨\n",
        "\n",
        "### ë°°í¬ ê³ ë ¤ì‚¬í•­\n",
        "- **ë°ì´í„° ë“œë¦¬í”„íŠ¸** ëª¨ë‹ˆí„°ë§(ë¶„í¬ ë³€í™” ê°ì§€)\n",
        "- **ì¬í•™ìŠµ ì£¼ê¸°** ê´€ë¦¬(ì›”/ë¶„ê¸°)\n",
        "- **ëª¨ë¸ ë²„ì „ ê´€ë¦¬** ë° ìŠ¹ì¸ í”„ë¡œì„¸ìŠ¤\n",
        "- **ë¦¬ìŠ¤í¬ í•œë„**ì™€ì˜ ì—°ê³„(ëª¨ë¸ ê²°ê³¼ë¥¼ ì •ì±…ì— ë§¤í•‘)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "beee8383",
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# 11. í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ (GridSearchCV)\n",
        "# =============================================================================\n",
        "# í•™ìŠµ ëª©í‘œ: ëª¨ë¸ ì„±ëŠ¥ì„ ê°œì„ í•˜ê¸° ìœ„í•´ ìµœì  íŒŒë¼ë¯¸í„°ë¥¼ íƒìƒ‰í•œë‹¤\n",
        "# Java ë¹„ìœ : ì„¤ì •ê°’ì„ ì¡°í•©í•´ ìµœì  ì„±ëŠ¥ì„ ì°¾ëŠ” íŠœë‹ ì‹¤í—˜ê³¼ ìœ ì‚¬\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import joblib\n",
        "\n",
        "# ê³µí†µ ì „ì²˜ë¦¬ + ëª¨ë¸ íŒŒì´í”„ë¼ì¸ ìƒì„± í•¨ìˆ˜\n",
        "\n",
        "def build_full_pipeline(model) -> Pipeline:\n",
        "    return Pipeline(\n",
        "        steps=[\n",
        "            (\"preprocess\", preprocess_pipeline.named_steps[\"preprocess\"]),\n",
        "            (\"model\", model),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "# Random Forest GridSearch\n",
        "rf_param_grid = {\n",
        "    \"model__n_estimators\": [100, 200, 300],\n",
        "    \"model__max_depth\": [10, 20, 30, None],\n",
        "    \"model__min_samples_split\": [2, 5, 10],\n",
        "}\n",
        "\n",
        "rf_grid = GridSearchCV(\n",
        "    estimator=build_full_pipeline(RandomForestClassifier(random_state=42)),\n",
        "    param_grid=rf_param_grid,\n",
        "    scoring=\"roc_auc\",\n",
        "    cv=5,\n",
        "    n_jobs=-1,\n",
        "    verbose=1,\n",
        ")\n",
        "\n",
        "rf_grid.fit(X_train, y_train)\n",
        "print(\"âœ… Random Forest ìµœì  íŒŒë¼ë¯¸í„°:\", rf_grid.best_params_)\n",
        "print(\"âœ… Random Forest ìµœê³  AUC:\", rf_grid.best_score_)\n",
        "\n",
        "# XGBoost GridSearch (ì„¤ì¹˜ëœ ê²½ìš°ë§Œ)\n",
        "if xgb is not None:\n",
        "    xgb_param_grid = {\n",
        "        \"model__learning_rate\": [0.01, 0.1, 0.3],\n",
        "        \"model__max_depth\": [3, 5, 7],\n",
        "        \"model__n_estimators\": [100, 200, 300],\n",
        "    }\n",
        "\n",
        "    xgb_grid = GridSearchCV(\n",
        "        estimator=build_full_pipeline(\n",
        "            xgb.XGBClassifier(\n",
        "                eval_metric=\"logloss\",\n",
        "                random_state=42,\n",
        "                subsample=0.8,\n",
        "                colsample_bytree=0.8,\n",
        "            )\n",
        "        ),\n",
        "        param_grid=xgb_param_grid,\n",
        "        scoring=\"roc_auc\",\n",
        "        cv=5,\n",
        "        n_jobs=-1,\n",
        "        verbose=1,\n",
        "    )\n",
        "\n",
        "    xgb_grid.fit(X_train, y_train)\n",
        "    print(\"âœ… XGBoost ìµœì  íŒŒë¼ë¯¸í„°:\", xgb_grid.best_params_)\n",
        "    print(\"âœ… XGBoost ìµœê³  AUC:\", xgb_grid.best_score_)\n",
        "else:\n",
        "    xgb_grid = None\n",
        "    print(\"âš ï¸ XGBoostê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•„ íŠœë‹ì„ ìŠ¤í‚µí•©ë‹ˆë‹¤.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b0d9178",
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# 12. Feature Importance (Random Forest)\n",
        "# =============================================================================\n",
        "# í•™ìŠµ ëª©í‘œ: ëª¨ë¸ì´ ì¤‘ìš”í•˜ê²Œ ë³´ëŠ” ë³€ìˆ˜ë¥¼ íŒŒì•…í•œë‹¤\n",
        "# Java ë¹„ìœ : ì¤‘ìš”ë„ê°€ ë†’ì€ í•„ë“œë¥¼ ìš°ì„ ì ìœ¼ë¡œ ê²€í† í•˜ëŠ” ì½”ë“œ ë¦¬ë·°ì™€ ìœ ì‚¬\n",
        "\n",
        "# GridSearch ê²°ê³¼ê°€ ìˆìœ¼ë©´ ìµœì  ëª¨ë¸ ì‚¬ìš©, ì—†ìœ¼ë©´ ê¸°ë³¸ RF ì‚¬ìš©\n",
        "best_rf_model = rf_grid.best_estimator_ if \"rf_grid\" in globals() else None\n",
        "if best_rf_model is None:\n",
        "    best_rf_model = build_full_pipeline(RandomForestClassifier(random_state=42))\n",
        "    best_rf_model.fit(X_train, y_train)\n",
        "\n",
        "# ì „ì²˜ë¦¬ëœ feature ì´ë¦„ ì¶”ì¶œ\n",
        "preprocess = best_rf_model.named_steps[\"preprocess\"]\n",
        "feature_names = preprocess.get_feature_names_out()\n",
        "\n",
        "# ëª¨ë¸ì˜ feature_importances_ ì¶”ì¶œ\n",
        "rf_model = best_rf_model.named_steps[\"model\"]\n",
        "importances = rf_model.feature_importances_\n",
        "\n",
        "feature_importance_df = pd.DataFrame(\n",
        "    {\"feature\": feature_names, \"importance\": importances}\n",
        ").sort_values(by=\"importance\", ascending=False)\n",
        "\n",
        "# ìƒìœ„ 10ê°œ ì¤‘ìš” ë³€ìˆ˜\n",
        "top_features = feature_importance_df.head(10)\n",
        "print(\"âœ… ìƒìœ„ 10ê°œ ì¤‘ìš” ë³€ìˆ˜\")\n",
        "print(top_features)\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.barplot(data=top_features, x=\"importance\", y=\"feature\")\n",
        "plt.title(\"Random Forest ì¤‘ìš” ë³€ìˆ˜ Top 10\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d98e9b6",
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# 13. SHAP Values (ì„ íƒ)\n",
        "# =============================================================================\n",
        "# í•™ìŠµ ëª©í‘œ: ê°œë³„ ì˜ˆì¸¡ì˜ ì›ì¸ì„ ì„¤ëª…í•  ìˆ˜ ìˆë‹¤\n",
        "# Java ë¹„ìœ : ë¡œê¹…/íŠ¸ë ˆì´ì‹±ìœ¼ë¡œ ì˜ì‚¬ê²°ì • ê·¼ê±°ë¥¼ ì¶”ì í•˜ëŠ” ë°©ì‹ê³¼ ìœ ì‚¬\n",
        "\n",
        "try:\n",
        "    import shap\n",
        "\n",
        "    # SHAP ê³„ì‚°ìš© ë°ì´í„° ìƒ˜í”Œë§ (ì†ë„ ê°œì„ )\n",
        "    sample_size = min(500, X_train.shape[0])\n",
        "    X_sample = X_train.sample(n=sample_size, random_state=42)\n",
        "\n",
        "    # ì „ì²˜ë¦¬ ë³€í™˜ ì ìš©\n",
        "    X_sample_prepared = preprocess.transform(X_sample)\n",
        "\n",
        "    # Tree ê¸°ë°˜ ëª¨ë¸ì— ì í•©í•œ Explainer ì‚¬ìš©\n",
        "    explainer = shap.TreeExplainer(rf_model)\n",
        "    shap_values = explainer.shap_values(X_sample_prepared)\n",
        "\n",
        "    # ìš”ì•½ í”Œë¡¯\n",
        "    shap.summary_plot(shap_values[1], X_sample_prepared, feature_names=feature_names)\n",
        "\n",
        "    # ê°œë³„ ì˜ˆì¸¡ ì„¤ëª… (ì²« ë²ˆì§¸ ìƒ˜í”Œ)\n",
        "    shap.force_plot(\n",
        "        explainer.expected_value[1],\n",
        "        shap_values[1][0],\n",
        "        X_sample_prepared[0],\n",
        "        feature_names=feature_names,\n",
        "        matplotlib=True,\n",
        "    )\n",
        "\n",
        "except ModuleNotFoundError:\n",
        "    print(\"âš ï¸ shap ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. (pip install shap)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "26deace2",
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# 14. ìµœì¢… ëª¨ë¸ ì €ì¥\n",
        "# =============================================================================\n",
        "# í•™ìŠµ ëª©í‘œ: ìµœì  ëª¨ë¸ì„ íŒŒì¼ë¡œ ì €ì¥í•´ ë°°í¬/ì¬ì‚¬ìš©í•œë‹¤\n",
        "# Java ë¹„ìœ : í•™ìŠµëœ ê°ì²´ë¥¼ ì§ë ¬í™”í•˜ì—¬ ì¬ì‚¬ìš©í•˜ëŠ” ë°©ì‹ê³¼ ìœ ì‚¬\n",
        "\n",
        "# ìµœì  ëª¨ë¸ ì„ íƒ: XGBoost > RandomForest ê¸°ì¤€ (ê°€ëŠ¥í•œ ê²½ìš°)\n",
        "if xgb_grid is not None:\n",
        "    best_model_pipeline = xgb_grid.best_estimator_\n",
        "    best_model_name = \"XGBoost\"\n",
        "else:\n",
        "    best_model_pipeline = rf_grid.best_estimator_\n",
        "    best_model_name = \"RandomForest\"\n",
        "\n",
        "model_path = Path.cwd() / \"best_credit_model.pkl\"\n",
        "joblib.dump(best_model_pipeline, model_path)\n",
        "print(f\"âœ… ìµœì¢… ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {model_path} ({best_model_name})\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
